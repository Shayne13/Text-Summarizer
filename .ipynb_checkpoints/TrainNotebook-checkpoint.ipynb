{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from parser import *\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "from itertools import izip\n",
    "import scipy\n",
    "import scipy.spatial.distance\n",
    "from numpy.linalg import svd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectFpr, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from summanlp_textrank import commons, graph, keywords, pagerank_weighted, \\\n",
    "                  summarizer, textrank, textcleaner, textrank_runtime_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputXML = \"sample_1\"\n",
    "# inputXML = \"sample_rawXML\"\n",
    "summaryFolder = \"sample_summary\"\n",
    "bodyFolder = \"sample_body\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "STAGE [1] -- PARSING XML -- from sample_1 ...\n",
      "STAGE [2] -- PROCESSING DATA -- (tokenizing/tagging/stopwords/extracting) ...\n"
     ]
    }
   ],
   "source": [
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "# PARSE:\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "documents, labels = parse_xml_folder(inputXML, summaryFolder, bodyFolder, writeOption='none')\n",
    "surfaceFeatures = process_data(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(documents, surfaceFeatures):\n",
    "    print \"STAGE [3] -- FEATURIZING -- (TextRank, LexRank, LDA) ...\"\n",
    "    features = []\n",
    "    for docIndex, doc in enumerate(documents):\n",
    "        documentFeatures = extract_document_wide_features(doc)\n",
    "        documentFeatures.append(surfaceFeatures[docIndex])\n",
    "        features += [ counter_sum(fl) for fl in izip(*documentFeatures) ]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_document_wide_features(document):\n",
    "    documentFeatures = []\n",
    "\n",
    "    documentFeatures.append(textrank_keyphrase(document))\n",
    "    documentFeatures.append(lexrank_keyphrase(document))\n",
    "    documentFeatures.append(textrank_keyword(document))\n",
    "\n",
    "    return documentFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counter_sum(counterTuple):\n",
    "    counterSum = Counter()\n",
    "    for ele in counterTuple:\n",
    "        counterSum += ele\n",
    "    return counterSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textrank_keyphrase(text):\n",
    "\n",
    "    # Creates the graph and calculates the similarity coefficient for every pair of nodes.\n",
    "    graph = commons.build_graph([ syntacticUnit for syntacticUnit in text])\n",
    "    summarizer._set_graph_edge_weights(graph)\n",
    "    # Remove all nodes with all edges weights equal to zero.\n",
    "    commons.remove_unreachable_nodes(graph)\n",
    "\n",
    "    # Ranks the tokens using the PageRank algorithm. Returns dict of sentence -> score\n",
    "    pagerank_scores = summarizer._pagerank(graph)\n",
    "\n",
    "    # Adds the summa scores to the sentence objects.\n",
    "    # summarizer._add_scores_to_sentences(sentences, pagerank_scores)\n",
    "\n",
    "    results = []\n",
    "    for su in text:\n",
    "        score = (1-pagerank_scores[su.label, su.index]) if (su.label, su.index) in pagerank_scores.keys() else 0.0\n",
    "        results.append(Counter({ 'TEXTRANK_SCORE': score }))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textrank_keyword(text):\n",
    "    txt = u' '.join([ su.text for su in text ])\n",
    "    # Gets a dict of word -> lemma\n",
    "    tokens = textcleaner.clean_text_by_word(text, 'english')\n",
    "    split_text = list(textcleaner.tokenize_by_word(txt))\n",
    "\n",
    "    # Creates the graph and adds the edges\n",
    "    graph = commons.build_graph(keywords._get_words_for_graph(tokens))\n",
    "    keywords._set_graph_edges(graph, tokens, split_text)\n",
    "    del split_text # It's no longer used\n",
    "    commons.remove_unreachable_nodes(graph)\n",
    "\n",
    "    # # Ranks the tokens using the PageRank algorithm. Returns dict of lemma -> score\n",
    "    pagerank_scores = keywords._pagerank_word(graph)\n",
    "    extracted_lemmas = keywords._extract_tokens(graph.nodes(), pagerank_scores, 0.2, None)\n",
    "    lemmas_to_word = keywords._lemmas_to_words(tokens)\n",
    "    keyWords = keywords._get_keywords_with_score(extracted_lemmas, lemmas_to_word)\n",
    "    # # text.split() to keep numbers and punctuation marks, so separeted concepts are not combined\n",
    "    combined_keywords = keywords._get_combined_keywords(keyWords, txt.split())\n",
    "    kw_scores = keywords._format_results(keyWords, combined_keywords, False, True)\n",
    "\n",
    "    results = [ Counter({ 'TEXTRANK_KEYWORD_SCORE': keyword_mean_score(su.basic, kw_scores) }) for su in text ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keyword_mean_score(sentence, wordScores):\n",
    "    totalScore = sum([ s for w, s in wordScores if w in sentence ])\n",
    "    return totalScore / len(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexrank_keyphrase(text):\n",
    "    results = []\n",
    "    for i in range(len(text)):\n",
    "        results.append(Counter({ 'LEXRANK_SCORE': 0.0 }))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(features, labels):\n",
    "    print \"STAGE [4] -- TRAINING MODEL -- Logistic Regression ...\"\n",
    "    print '<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>'\n",
    "    vectorizer = DictVectorizer(sparse=False)\n",
    "    feature_matrix = vectorizer.fit_transform(features) # Features = List of counters\n",
    "    mod = LogisticRegression(fit_intercept=True, intercept_scaling=1, class_weight='auto')\n",
    "    mod.fit_transform(feature_matrix, labels)\n",
    "    return mod, feature_matrix, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE [3] -- FEATURIZING -- (TextRank, LexRank, LDA) ...\n",
      "STAGE [4] -- TRAINING MODEL -- Logistic Regression ...\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "[[-0.1107776  -0.44076819 -0.51537521 -0.26291182 -0.40936365 -0.65803028\n",
      "   0.8746662   0.47629844  0.38003429 -0.43231561 -0.16282134  0.50850067\n",
      "  -0.28099118  0.5485241   0.11009769 -0.06869526  0.31151657  0.20628777\n",
      "   0.12439831 -0.2521433   0.14399234  1.24799225 -0.08775069 -0.47208916]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       BODY       0.96      0.69      0.80       330\n",
      "    SUMMARY       0.17      0.67      0.26        30\n",
      "\n",
      "avg / total       0.89      0.69      0.76       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "# TRAIN:\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "features = featurize(documents, surfaceFeatures)\n",
    "# del surfaceFeatures\n",
    "model, featMatrix, vectorizer = train_classifier(features, labels)\n",
    "\n",
    "scores = cross_val_score(model, featMatrix, labels, scoring=\"f1_macro\") # accuracy, f1, log_loss\n",
    "print model.coef_\n",
    "predictions = model.predict(featMatrix)\n",
    "print metrics.classification_report(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "STAGE [1] -- PARSING XML -- from sample_test ...\n",
      "STAGE [2] -- PROCESSING DATA -- (tokenizing/tagging/stopwords/extracting) ...\n"
     ]
    }
   ],
   "source": [
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "# TEST:\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "testXMLFolder = \"sample_test\"\n",
    "testDocuments, testLabels = parse_xml_folder(testXMLFolder, summaryFolder, bodyFolder, writeOption='none')\n",
    "testSurfaceFeatures = process_data(testDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE [3] -- FEATURIZING -- (TextRank, LexRank, LDA) ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name '_strip_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5a80ff77e856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtestFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestSurfaceFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mtestFeatureMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestFeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Features = List of counters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtestSurfaceFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-78922ff8cb22>\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(documents, surfaceFeatures)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdocIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdocumentFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_document_wide_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdocumentFeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurfaceFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mcounter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdocumentFeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b5b7256fd091>\u001b[0m in \u001b[0;36mextract_document_wide_features\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdocumentFeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextrank_keyphrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdocumentFeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexrank_keyphrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdocumentFeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextrank_keyword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdocumentFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-c34b868dff08>\u001b[0m in \u001b[0;36mtextrank_keyword\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mkeyWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_keywords_with_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_lemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmas_to_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# # text.split() to keep numbers and punctuation marks, so separeted concepts are not combined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcombined_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mour_get_combined_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mkw_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_keywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-5a80ff77e856>\u001b[0m in \u001b[0;36mour_get_combined_keywords\u001b[0;34m(_keywords, split_text)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlen_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strip_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_keywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mcombined_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name '_strip_word' is not defined"
     ]
    }
   ],
   "source": [
    "testFeatures = featurize(testDocuments, testSurfaceFeatures)\n",
    "testFeatureMatrix = vectorizer.transform(testFeatures) # Features = List of counters\n",
    "del testSurfaceFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_trained_classifier(model, feature_matrix, labels):\n",
    "    \"\"\"Evaluate model, the output of train_classifier, on the test data.\"\"\"\n",
    "    print \"STAGE [5] -- TESTING -- Logistic Regression ...\"\n",
    "    print '<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>'\n",
    "    predictions = model.predict(feature_matrix)\n",
    "    print cross_val_score(model, feature_matrix, labels, scoring=\"f1_macro\")\n",
    "    return metrics.classification_report(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print evaluate_trained_classifier(model, testFeatureMatrix, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_summary(document):\n",
    "    summary = []\n",
    "    for su in document:\n",
    "        if su.label == 'summary':\n",
    "            summary.append(su.text)\n",
    "        else:\n",
    "            break\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "def extract_top_ranked(document, featureMatrix, num):\n",
    "    predictions = model.predict_proba(featureMatrix)\n",
    "    itr = range(len(document))\n",
    "    topIndexes = nlargest(num, itr, key=lambda i: predictions[i][1])\n",
    "    topSentences = [ document[index].text for index in topIndexes]\n",
    "    return topSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featIndex = 0\n",
    "rouge_gold_summaries = []\n",
    "rouge_generated_summaries = []\n",
    "for i, tdoc in enumerate(testDocuments):\n",
    "    numSentences = len(tdoc)\n",
    "    rouge_gold_summaries.append(extract_summary(tdoc))\n",
    "    rouge_generated_summaries.append(extract_top_ranked(tdoc, testFeatureMatrix[featIndex:featIndex+numSentences], 10))\n",
    "    featIndex += numSentences\n",
    "\n",
    "#print rouge_gold_summaries\n",
    "#print rouge_generated_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from RougeRunner import *\n",
    "\n",
    "rougeResults = []\n",
    "\n",
    "for summaryIndex in range(len(rouge_gold_summaries)):\n",
    "    gold = rouge_gold_summaries[summaryIndex]\n",
    "    genSum = rouge_generated_summaries[summaryIndex]\n",
    "    rougeResults.append(compareUsingRouge(gold, genSum))\n",
    "    \n",
    "print rougeResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
