{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from parser import *\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "from itertools import izip\n",
    "import scipy\n",
    "import scipy.spatial.distance\n",
    "from numpy.linalg import svd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectFpr, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from summanlp_textrank import commons, graph, keywords, pagerank_weighted, \\\n",
    "                  summarizer, textrank, textcleaner, textrank_runtime_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputXML = \"sample_1\"\n",
    "# inputXML = \"sample_rawXML\"\n",
    "summaryFolder = \"sample_summary\"\n",
    "bodyFolder = \"sample_body\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "STAGE [1] -- PARSING XML -- from sample_1 ...\n",
      "STAGE [2] -- PROCESSING DATA -- (tokenizing/tagging/stopwords/extracting) ...\n"
     ]
    }
   ],
   "source": [
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "# PARSE:\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "documents, labels = parse_xml_folder(inputXML, summaryFolder, bodyFolder, writeOption='none')\n",
    "surfaceFeatures = process_data(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(documents, surfaceFeatures):\n",
    "    print \"STAGE [3] -- FEATURIZING -- (TextRank, LexRank, LDA) ...\"\n",
    "    features = []\n",
    "    for docIndex, doc in enumerate(documents):\n",
    "        documentFeatures = extract_document_wide_features(doc)\n",
    "        documentFeatures.append(surfaceFeatures[docIndex])\n",
    "        features += [ counter_sum(fl) for fl in izip(*documentFeatures) ]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_document_wide_features(document):\n",
    "    documentFeatures = []\n",
    "\n",
    "    documentFeatures.append(textrank_keyphrase(document))\n",
    "    documentFeatures.append(lexrank_keyphrase(document))\n",
    "    documentFeatures.append(textrank_keyword(document))\n",
    "\n",
    "    return documentFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counter_sum(counterTuple):\n",
    "    counterSum = Counter()\n",
    "    for ele in counterTuple:\n",
    "        counterSum += ele\n",
    "    return counterSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textrank_keyphrase(text):\n",
    "\n",
    "    # Creates the graph and calculates the similarity coefficient for every pair of nodes.\n",
    "    graph = commons.build_graph([ syntacticUnit for syntacticUnit in text])\n",
    "    summarizer._set_graph_edge_weights(graph)\n",
    "    # Remove all nodes with all edges weights equal to zero.\n",
    "    commons.remove_unreachable_nodes(graph)\n",
    "\n",
    "    # Ranks the tokens using the PageRank algorithm. Returns dict of sentence -> score\n",
    "    pagerank_scores = summarizer._pagerank(graph)\n",
    "\n",
    "    # Adds the summa scores to the sentence objects.\n",
    "    # summarizer._add_scores_to_sentences(sentences, pagerank_scores)\n",
    "\n",
    "    results = []\n",
    "    for su in text:\n",
    "        score = (1-pagerank_scores[su.label, su.index]) if (su.label, su.index) in pagerank_scores.keys() else 0.0\n",
    "        results.append(Counter({ 'TEXTRANK_SCORE': score }))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textrank_keyword(text):\n",
    "    txt = u' '.join([ su.text for su in text ])\n",
    "    # Gets a dict of word -> lemma\n",
    "    tokens = textcleaner.clean_text_by_word(text, 'english')\n",
    "    split_text = list(textcleaner.tokenize_by_word(txt))\n",
    "\n",
    "    # Creates the graph and adds the edges\n",
    "    graph = commons.build_graph(keywords._get_words_for_graph(tokens))\n",
    "    keywords._set_graph_edges(graph, tokens, split_text)\n",
    "    del split_text # It's no longer used\n",
    "    commons.remove_unreachable_nodes(graph)\n",
    "\n",
    "    # # Ranks the tokens using the PageRank algorithm. Returns dict of lemma -> score\n",
    "    pagerank_scores = keywords._pagerank_word(graph)\n",
    "    extracted_lemmas = keywords._extract_tokens(graph.nodes(), pagerank_scores, 0.2, None)\n",
    "    lemmas_to_word = keywords._lemmas_to_words(tokens)\n",
    "    keyWords = keywords._get_keywords_with_score(extracted_lemmas, lemmas_to_word)\n",
    "    # # text.split() to keep numbers and punctuation marks, so separeted concepts are not combined\n",
    "    combined_keywords = keywords._get_combined_keywords(keyWords, txt.split())\n",
    "    kw_scores = keywords._format_results(keyWords, combined_keywords, False, True)\n",
    "\n",
    "    results = [ Counter({ 'TEXTRANK_KEYWORD_SCORE': keyword_mean_score(su.basic, kw_scores) }) for su in text ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keyword_mean_score(sentence, wordScores):\n",
    "    totalScore = sum([ s for w, s in wordScores if w in sentence ])\n",
    "    return totalScore / len(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexrank_keyphrase(text):\n",
    "    results = []\n",
    "    for i in range(len(text)):\n",
    "        results.append(Counter({ 'LEXRANK_SCORE': 0.0 }))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(features, labels):\n",
    "    print \"STAGE [4] -- TRAINING MODEL -- Logistic Regression ...\"\n",
    "    print '<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>'\n",
    "    vectorizer = DictVectorizer(sparse=False)\n",
    "    feature_matrix = vectorizer.fit_transform(features) # Features = List of counters\n",
    "    mod = LogisticRegression(fit_intercept=True, intercept_scaling=1, class_weight='auto')\n",
    "    mod.fit_transform(feature_matrix, labels)\n",
    "    return mod, feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE [3] -- FEATURIZING -- (TextRank, LexRank, LDA) ...\n",
      "STAGE [4] -- TRAINING MODEL -- Logistic Regression ...\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "[[-0.07702519 -0.15453099 -0.25571491  0.01753503  0.1711909  -0.02846504\n",
      "   0.68764793  0.81465759 -0.18590128 -0.42057279  0.06774776 -0.59821813\n",
      "   0.3894049  -0.21775336  0.04138842  0.27759811 -0.03553251  0.06351103\n",
      "  -0.398737    0.20133042  0.62481678 -0.10930073 -0.27369215]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       BODY       0.96      0.70      0.81       151\n",
      "    SUMMARY       0.15      0.67      0.24        12\n",
      "\n",
      "avg / total       0.90      0.69      0.77       163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "# TRAIN:\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "features = featurize(documents, surfaceFeatures)\n",
    "model, featMatrix = train_classifier(features, labels)\n",
    "\n",
    "scores = cross_val_score(model, featMatrix, labels, scoring=\"f1_macro\") # accuracy, f1, log_loss\n",
    "print model.coef_\n",
    "predictions = model.predict(featMatrix)\n",
    "print metrics.classification_report(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It uses a hybrid of traditional cel animation and rotoscoped live action footage.\n",
      "[(u'hybrid', 'JJ'), (u'traditional', 'JJ'), (u'cel', 'NN'), (u'animation', 'NN'), (u'live', 'JJ'), (u'action', 'NN'), (u'footage', 'NN')]\n",
      "summary\n",
      "2\n",
      "SUMMARY\n",
      "Counter({'CONTAINS_WORD_TYPE_VB': 1.0, 'CONTAINS_WORD_TYPE_NN': 1.0, 'SENTENCE_LENGTH_2': 1.0, 'CONTAINS_WORD_TYPE_JJ': 1.0, 'CONTAINS_PUNCTUATION_.': 1.0, 'TEXTRANK_SCORE': 0.97408521307294482, 'WORD_RATIO_NN': 0.36363636363636365, 'WORD_RATIO_JJ': 0.2727272727272727, 'WORD_RATIO_VB': 0.18181818181818182, 'TEXTRANK_KEYWORD_SCORE': 0.031252926496807477})\n"
     ]
    }
   ],
   "source": [
    "print documents[0][2].text\n",
    "print documents[0][2].processed\n",
    "print documents[0][2].label\n",
    "print documents[0][2].index\n",
    "print predictions[2]\n",
    "print features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          1.          0.          0.\n",
      "  1.          1.          0.          0.          1.          0.          0.\n",
      "  1.          0.          0.          0.97408521  0.27272727  0.36363636\n",
      "  0.          0.18181818]\n"
     ]
    }
   ],
   "source": [
    "print featMatrix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SUMMARY: +ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
