{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from parser import *\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "from itertools import izip\n",
    "import scipy\n",
    "import scipy.spatial.distance\n",
    "from numpy.linalg import svd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectFpr, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from summanlp_textrank import commons, graph, keywords, pagerank_weighted, \\\n",
    "                  summarizer, textrank, textcleaner, textrank_runtime_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputXML = \"sample_1\"\n",
    "# inputXML = \"sample_rawXML\"\n",
    "summaryFolder = \"sample_summary\"\n",
    "bodyFolder = \"sample_body\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "STAGE [1] -- PARSING XML -- from sample_1 ...\n",
      "STAGE [2] -- PROCESSING DATA -- (tokenizing/tagging/stopwords/extracting) ...\n"
     ]
    }
   ],
   "source": [
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "# PARSE:\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "documents, labels = parse_xml_folder(inputXML, summaryFolder, bodyFolder, writeOption='none')\n",
    "surfaceFeatures = process_data(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(documents, surfaceFeatures):\n",
    "    print \"STAGE [3] -- FEATURIZING -- (TextRank, LexRank, LDA) ...\"\n",
    "    features = []\n",
    "    for docIndex, doc in enumerate(documents):\n",
    "        documentFeatures = extract_document_wide_features(doc)\n",
    "        documentFeatures.append(surfaceFeatures[docIndex])\n",
    "        features += [ counter_sum(fl) for fl in izip(*documentFeatures) ]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_document_wide_features(document):\n",
    "    documentFeatures = []\n",
    "\n",
    "    documentFeatures.append(textrank_keyphrase(document))\n",
    "    documentFeatures.append(lexrank_keyphrase(document))\n",
    "    documentFeatures.append(textrank_keyword(document))\n",
    "\n",
    "    return documentFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counter_sum(counterTuple):\n",
    "    counterSum = Counter()\n",
    "    for ele in counterTuple:\n",
    "        counterSum += ele\n",
    "    return counterSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textrank_keyphrase(text):\n",
    "\n",
    "    # Creates the graph and calculates the similarity coefficient for every pair of nodes.\n",
    "    graph = commons.build_graph([ syntacticUnit for syntacticUnit in text])\n",
    "    summarizer._set_graph_edge_weights(graph)\n",
    "    # Remove all nodes with all edges weights equal to zero.\n",
    "    commons.remove_unreachable_nodes(graph)\n",
    "\n",
    "    # Ranks the tokens using the PageRank algorithm. Returns dict of sentence -> score\n",
    "    pagerank_scores = summarizer._pagerank(graph)\n",
    "\n",
    "    # Adds the summa scores to the sentence objects.\n",
    "    # summarizer._add_scores_to_sentences(sentences, pagerank_scores)\n",
    "\n",
    "    results = []\n",
    "    for su in text:\n",
    "        score = (1-pagerank_scores[su.label, su.index]) if (su.label, su.index) in pagerank_scores.keys() else 0.0\n",
    "        results.append(Counter({ 'TEXTRANK_SCORE': score }))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textrank_keyword(text):\n",
    "    txt = u' '.join([ su.text for su in text ])\n",
    "    # Gets a dict of word -> lemma\n",
    "    tokens = textcleaner.clean_text_by_word(text, 'english')\n",
    "    split_text = list(textcleaner.tokenize_by_word(txt))\n",
    "\n",
    "    # Creates the graph and adds the edges\n",
    "    graph = commons.build_graph(keywords._get_words_for_graph(tokens))\n",
    "    keywords._set_graph_edges(graph, tokens, split_text)\n",
    "    del split_text # It's no longer used\n",
    "    commons.remove_unreachable_nodes(graph)\n",
    "\n",
    "    # # Ranks the tokens using the PageRank algorithm. Returns dict of lemma -> score\n",
    "    pagerank_scores = keywords._pagerank_word(graph)\n",
    "    extracted_lemmas = keywords._extract_tokens(graph.nodes(), pagerank_scores, 0.2, None)\n",
    "    lemmas_to_word = keywords._lemmas_to_words(tokens)\n",
    "    keyWords = keywords._get_keywords_with_score(extracted_lemmas, lemmas_to_word)\n",
    "    # # text.split() to keep numbers and punctuation marks, so separeted concepts are not combined\n",
    "    combined_keywords = keywords._get_combined_keywords(keyWords, txt.split())\n",
    "    kw_scores = keywords._format_results(keyWords, combined_keywords, False, True)\n",
    "\n",
    "    results = [ Counter({ 'TEXTRANK_KEYWORD_SCORE': keyword_mean_score(su.basic, kw_scores) }) for su in text ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keyword_mean_score(sentence, wordScores):\n",
    "    totalScore = sum([ s for w, s in wordScores if w in sentence ])\n",
    "    return totalScore / len(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexrank_keyphrase(text):\n",
    "    results = []\n",
    "    for i in range(len(text)):\n",
    "        results.append(Counter({ 'LEXRANK_SCORE': 0.0 }))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(features, labels):\n",
    "    print \"STAGE [4] -- TRAINING MODEL -- Logistic Regression ...\"\n",
    "    print '<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>'\n",
    "    vectorizer = DictVectorizer(sparse=False)\n",
    "    feature_matrix = vectorizer.fit_transform(features) # Features = List of counters\n",
    "    mod = LogisticRegression(fit_intercept=True, intercept_scaling=1, class_weight='auto')\n",
    "    mod.fit_transform(feature_matrix, labels)\n",
    "    return mod, feature_matrix, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE [3] -- FEATURIZING -- (TextRank, LexRank, LDA) ...\n",
      "STAGE [4] -- TRAINING MODEL -- Logistic Regression ...\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "[[-0.06978593 -0.15334872 -0.25510274  0.0126926   0.1922343  -0.24831293\n",
      "  -0.02436139  0.68096096  0.79596326 -0.22309355 -0.43292563  0.05515176\n",
      "  -0.61671967  0.36719587 -0.24619082  0.022105    0.26400959 -0.03795395\n",
      "   0.06248649 -0.43588031  0.1884946   0.60676931 -0.11005708 -0.28079814]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       BODY       0.96      0.72      0.82       151\n",
      "    SUMMARY       0.16      0.67      0.25        12\n",
      "\n",
      "avg / total       0.90      0.71      0.78       163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "# TRAIN:\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "features = featurize(documents, surfaceFeatures)\n",
    "# del surfaceFeatures\n",
    "model, featMatrix, vectorizer = train_classifier(features, labels)\n",
    "\n",
    "scores = cross_val_score(model, featMatrix, labels, scoring=\"f1_macro\") # accuracy, f1, log_loss\n",
    "print model.coef_\n",
    "predictions = model.predict(featMatrix)\n",
    "print metrics.classification_report(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "STAGE [1] -- PARSING XML -- from sample_test ...\n",
      "STAGE [2] -- PROCESSING DATA -- (tokenizing/tagging/stopwords/extracting) ...\n"
     ]
    }
   ],
   "source": [
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "# TEST:\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "testXMLFolder = \"sample_test\"\n",
    "testDocuments, testLabels = parse_xml_folder(testXMLFolder, summaryFolder, bodyFolder, writeOption='none')\n",
    "testSurfaceFeatures = process_data(testDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE [3] -- FEATURIZING -- (TextRank, LexRank, LDA) ...\n"
     ]
    }
   ],
   "source": [
    "testFeatures = featurize(testDocuments, testSurfaceFeatures)\n",
    "testFeatureMatrix = vectorizer.transform(testFeatures) # Features = List of counters\n",
    "del testSurfaceFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_trained_classifier(model, feature_matrix, labels):\n",
    "    \"\"\"Evaluate model, the output of train_classifier, on the test data.\"\"\"\n",
    "    print \"STAGE [5] -- TESTING -- Logistic Regression ...\"\n",
    "    print '<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>'\n",
    "    predictions = model.predict(feature_matrix)\n",
    "    print cross_val_score(model, feature_matrix, labels, scoring=\"f1_macro\")\n",
    "    return metrics.classification_report(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE [5] -- TESTING -- Logistic Regression ...\n",
      "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
      "[ 0.50747757  0.45185185  0.55555556]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       BODY       0.91      0.58      0.71       100\n",
      "    SUMMARY       0.11      0.45      0.17        11\n",
      "\n",
      "avg / total       0.83      0.57      0.65       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print evaluate_trained_classifier(model, testFeatureMatrix, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_summary(document):\n",
    "    summary = []\n",
    "    for su in document:\n",
    "        if su.label == 'summary':\n",
    "            summary.append(su.text)\n",
    "        else:\n",
    "            break\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "def extract_top_ranked(document, featureMatrix, num):\n",
    "    predictions = model.predict_proba(featureMatrix)\n",
    "    itr = range(len(document))\n",
    "    topIndexes = nlargest(num, itr, key=lambda i: predictions[i][1])\n",
    "    topSentences = [ document[index].text for index in topIndexes]\n",
    "    return topSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'The Most Illustrious Order of Saint Patrick is a British order of chivalry associated with Ireland.', u'The Order was created in 1783 by George III.', u'The regular creation of knights of Saint Patrick lasted until 1921, when most of Ireland became independent as the Irish Free State.', u'While the Order technically still exists, no knight of St Patrick has been created since 1936, and the last surviving knight, Prince Henry, Duke of Gloucester, died in 1974.', u'The Queen, however, remains the Sovereign of the Order, and one officer, the Ulster King of Arms (now combined with Norroy King of Arms), also survives.', u'St Patrick is patron of the order; its motto is Quis separabit?, Latin for \"Who will separate us?', u'\": an allusion to the Vulgate translation of Romans 8:35, \"Who shall separate us from the love of Christ?\"', u'Most British orders of chivalry cover the entire kingdom, but the three most exalted ones each pertain to one constituent nation only.', u'The Order of St Patrick, which pertains to Ireland, is the most junior of these three in precedence and age.', u'Its equivalent in England, The Most Noble Order of the Garter, is the oldest order of chivalry in the United Kingdom, dating to the middle fourteenth century.', u'The Scottish equivalent is The Most Ancient and Most Noble Order of the Thistle, dating in its modern form to 1687.']]\n",
      "[[u'Most British orders of chivalry cover the entire kingdom, but the three most exalted ones each pertain to one constituent nation only.', u'The Order of St Patrick, which pertains to Ireland, is the most junior of these three in precedence and age.', u'The Duke of Gloucester at his death in 1974 was the last surviving member of the Order.', u'The Order of St Patrick had six other heraldic officers, many more than any other British order.', u'In the case of the stall plates this was perhaps due to the their size, 30x36 cm (12x14 in).', u'The Scottish equivalent is The Most Ancient and Most Noble Order of the Thistle, dating in its modern form to 1687.', u'The Irish post has been vacant since 1933.', u'The regular creation of knights of Saint Patrick lasted until 1921, when most of Ireland became independent as the Irish Free State.', u'The office of Secretary has been vacant since 1926.', u'In 1831, however, William IV presented the Grand Master with a star and badge, each composed of rubies, emeralds and Brazilian diamonds.']]\n"
     ]
    }
   ],
   "source": [
    "featIndex = 0\n",
    "rouge_gold_summaries = []\n",
    "rouge_generated_summaries = []\n",
    "for i, tdoc in enumerate(testDocuments):\n",
    "    numSentences = len(tdoc)\n",
    "    rouge_gold_summaries.append(extract_summary(tdoc))\n",
    "    rouge_generated_summaries.append(extract_top_ranked(tdoc, testFeatureMatrix[featIndex:featIndex+numSentences], 10))\n",
    "    featIndex += numSentences\n",
    "\n",
    "print rouge_gold_summaries\n",
    "print rouge_generated_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
